[
  {
    "name": "Base English",
    "repo": "GitMylo/bark-voice-cloning",
    "file": "quantifier_hubert_base_ls960_14.pth",
    "language": "ENG",
    "author": "https://github.com/gitmylo/",
    "quant_version": 0,
    "official": true,
    "dlfilename": "tokenizer.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/GitMylo/bark-semantic-training"
    }
  },
  {
    "name": "Large English",
    "repo": "GitMylo/bark-voice-cloning",
    "file": "quantifier_V1_hubert_base_ls960_23.pth",
    "language": "ENG",
    "author": "https://github.com/gitmylo/",
    "quant_version": 1,
    "official": true,
    "dlfilename": "tokenizer_large.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/GitMylo/bark-semantic-training"
    }
  },
  {
    "name": "Polish",
    "repo": "Hobis/bark-voice-cloning-polish-HuBERT-quantizer",
    "file": "polish-HuBERT-quantizer_8_epoch.pth",
    "language": "POL",
    "author": "https://github.com/HobisPL",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_pol.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/Hobis/bark-polish-semantic-wav-training"
    }
  },
  {
    "name": "German",
    "repo": "CountFloyd/bark-voice-cloning-german-HuBERT-quantizer",
    "file": "german-HuBERT-quantizer_14_epoch.pth",
    "language": "GER",
    "author": "https://github.com/C0untFloyd",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_ger.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/CountFloyd/bark-german-semantic-wav-training"
    }
  },
  {
    "name": "Spanish",
    "repo": "Lancer1408/bark-es-tokenizer",
    "file": "es_tokenizer.pth",
    "language": "SPA",
    "author": "https://github.com/MaxLanc",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_spa.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/Lancer1408/bark-spa-token-trainy"
    }
  },
  {
    "name": "Portuguese",
    "repo": "MadVoyager/bark-voice-cloning-portuguese-HuBERT-quantizer",
    "file": "portuguese-HuBERT-quantizer_24_epoch.pth",
    "language": "POR",
    "author": "https://github.com/Subarasheese",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_por.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/MadVoyager/bark-portuguese-semantic-wav-training/"
    }
  },
  {
    "name": "Japanese",
    "repo": "junwchina/bark-voice-cloning-japanese-HuBERT-quantizer",
    "file": "japanese-HuBERT-quantizer_24_epoch.pth",
    "language": "JA",
    "author": "https://github.com/junwchina",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_ja.pth",
    "extra": {
      "dataset": "https://huggingface.co/datasets/junwchina/bark-japanese-semantic-wav-training"
    }
  },
  {
    "name": "Turkish",
    "repo": "egeadam/bark-voice-cloning-turkish-HuBERT-quantizer",
    "file": "turkish_model_epoch_14.pth",
    "language": "TUR",
    "author": "https://github.com/ege-adam",
    "quant_version": 1,
    "official": false,
    "dlfilename": "tokenizer_tur.pth"
  },
  {
    "name": "Italian",
    "repo": "gpwr/bark-it-tokenizer",
    "file": "it_tokenizer.pth",
    "language": "ITA",
    "author": "https://github.com/gc-pwr",
    "quant_version": 1,
    "official": false,
    "dlfilename": "it_tokenizer.pth"
  }
]
